# -*- coding: utf-8 -*-
"""notebookd6fca8a3d9

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/mohammadtawsif/notebookd6fca8a3d9.b03d5fd8-18f4-4884-83c9-4dc25704e1e8.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250406/auto/storage/goog4_request%26X-Goog-Date%3D20250406T133745Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2ce2f8f64d93a5e0fd026e319e308a1c1589fc6589f85cc9d5c5a5f4a6780aa2ee7638b64836eeae0a5b3d937f49a3c50948b6516bb51417a0d16e268bd8f941db94a3bb534b424ef7e669e7c01dfe57080f18cf3c52910e66c7ae36b64f7b4f35b065ff5390c2ee9effab78556220be5569d6a0704159d4da9d5be15a5fce43ee1cebf8c2b538117beb18e5eb8c505518b2580020fc7fab7697b577100870435552135db30da2cbe5023ec4ca4fe131d5223484f1613f066126165cd82e5f7bfec5f01c43a034838fa6f3e56a4529df3eb5b5b54ada9a60c0d8404cdf735afa80b98bc627a92332432559fed86ecbd80bff5ec33a0b050d29875770fcd7cae3
"""

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from flask import Flask, request, jsonify, render_template
import joblib
from werkzeug.utils import secure_filename

# Initialize Flask app
app = Flask(__name__)

# Configuration
UPLOAD_FOLDER = 'static/uploads'
ALLOWED_EXTENSIONS = {'jpg', 'jpeg', 'png'}
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Load models with compatibility fixes
print("Loading model and preprocessing components...")
try:
    # Load with custom objects for compatibility
    with tf.keras.utils.custom_object_scope({
        'AdamW': tf.keras.optimizers.legacy.AdamW,
        'CosineDecay': tf.keras.optimizers.schedules.CosineDecay
    }):
        model = tf.keras.models.load_model('model.h5', compile=False)

    # Recompile model
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])

    # Load preprocessing components
    preprocessor = joblib.load('preprocessor.pkl')
    label_scaler = joblib.load('label_scaler.pkl')
    print("All components loaded successfully!")
except Exception as e:
    print(f"Error loading models: {str(e)}")
    raise e

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    if request.method == 'POST':
        try:
            # Check if image exists
            if 'image' not in request.files:
                return jsonify({'error': 'No image uploaded'}), 400

            file = request.files['image']
            if file.filename == '':
                return jsonify({'error': 'No selected image'}), 400

            if not allowed_file(file.filename):
                return jsonify({'error': 'Invalid file type'}), 400

            # Save image temporarily
            filename = secure_filename(file.filename)
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)

            # Process image
            img = load_img(filepath, target_size=(128, 128))
            img_array = img_to_array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)

            # Get form data
            data = request.form
            biomarkers = {
                'Height (cm)': float(data.get('height')),
                'Weight (kg)': float(data.get('weight')),
                'BMI': float(data.get('bmi')),
                'Blood Pressure (s/d)': data.get('blood_pressure'),
                'Blood Oxygen': float(data.get('blood_oxygen')),
                'Blood Sugar(mg/dl)': float(data.get('blood_sugar'))
            }

            # Create DataFrame with expected columns
            tabular_df = pd.DataFrame([biomarkers])

            # Process tabular data
            tabular_processed = preprocessor.transform(tabular_df)
            if hasattr(tabular_processed, 'toarray'):
                tabular_processed = tabular_processed.toarray()
            if len(tabular_processed.shape) == 1:
                tabular_processed = np.expand_dims(tabular_processed, axis=0)

            # Make prediction
            inputs = {
                'image_input': img_array,
                'tabular_input': tabular_processed.astype(np.float32)
            }

            prediction_scaled = model.predict(inputs)[0][0]
            predicted_age = label_scaler.inverse_transform([[prediction_scaled]])[0][0]

            # Clean up
            os.remove(filepath)

            return jsonify({
                'predicted_age': round(predicted_age, 1),
                'status': 'success'
            })

        except Exception as e:
            return jsonify({
                'error': str(e),
                'status': 'failed'
            }), 500

@app.errorhandler(404)
def not_found(e):
    return jsonify({'error': 'Endpoint not found'}), 404

@app.errorhandler(500)
def server_error(e):
    return jsonify({'error': 'Internal server error'}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)

